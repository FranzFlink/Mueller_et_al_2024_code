{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from haversine import haversine, Unit\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from tqdm import tqdm\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm, LogNorm\n",
    "import pandas as pd\n",
    "from xhistogram.xarray import histogram\n",
    "from sklearn.neighbors import KNeighborsRegressor, BallTree\n",
    "from scipy import stats\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import cmocean\n",
    "\n",
    "def haversine_sklearn(lat1, lon1, lat_array, lon_array):\n",
    "\n",
    "\n",
    "    X = np.array([lat1, lon1]).reshape(1, -1)\n",
    "    Y = np.array([lat_array, lon_array]).T\n",
    "    X = np.radians(X)\n",
    "    Y = np.radians(Y)\n",
    "\n",
    "    return haversine_distances(X, Y) * 6357\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "\n",
    "colors = np.array([[0.10588235, 0.61960784, 0.46666667, 1.],\n",
    "                [0.45882353, 0.43921569, 0.70196078, 1.],\n",
    "                [0.4       , 0.4       , 0.4       , 1.],\n",
    "                [0.90196078, 0.67058824, 0.00784314, 1.],\n",
    "])\n",
    "\n",
    "cmap = ListedColormap(colors)\n",
    "#cmap = plt.get_cmap('Dark2')\n",
    "bounds = [1, 2, 3, 4, 5]\n",
    "norm = BoundaryNorm(bounds, cmap.N)\n",
    "# Create a figure and axis with the specified size\n",
    "\n",
    "SIC = xr.open_dataset('/projekt_agmwend/home_rad/Joshua/HALO-AC3_unified_data/amsr_modis_sic.nc').sortby('time')\n",
    "ds = xr.open_dataset('../../data/ar/HALO-AC3_HALO_VELOX_segmentation_statistics_with_sea_ice_edge_distance.nc')\n",
    "\n",
    "\n",
    "fontsize = 8\n",
    "\n",
    "plt.rcParams['font.size'] = fontsize\n",
    "plt.rcParams['axes.labelsize']  = fontsize\n",
    "plt.rcParams['axes.titlesize']  = fontsize\n",
    "plt.rcParams['xtick.labelsize'] = fontsize\n",
    "plt.rcParams['ytick.labelsize'] = fontsize\n",
    "plt.rcParams['legend.fontsize'] = fontsize\n",
    "plt.rcParams['legend.title_fontsize'] = fontsize\n",
    "plt.rcParams['figure.titlesize'] = fontsize\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['axes.axisbelow'] = True\n",
    "sc_cmap = 'Dark2'\n",
    "\n",
    "cmap = ListedColormap(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfiles_keys = [f.split('_full')[0] for f in os.listdir(f'/projekt_agmwend/home_rad/Joshua/Mueller_et_al_2024/data/full_datasets/') if 'full' in f and 'T' in f]\n",
    "\n",
    "outfiles_keys.sort()\n",
    "\n",
    "outfiles = os.listdir('/projekt_agmwend/home_rad/Joshua/Mueller_et_al_2024/data/full_datasets/')\n",
    "outfiles = [f'/projekt_agmwend/home_rad/Joshua/Mueller_et_al_2024/data/full_datasets/{f}' for f in outfiles if 'full' in f and 'T' in f]\n",
    "outfiles.sort() \n",
    "\n",
    "segmentation_path = '/projekt_agmwend/home_rad/Joshua/Mueller_et_al_2024/data/segmented_data_nadir/'\n",
    "segmentation_files = [os.path.join(segmentation_path, f) for f in os.listdir(segmentation_path)]\n",
    "segmentation_files.sort()\n",
    "\n",
    "### compare the length\n",
    "len_outfiles = len(outfiles)\n",
    "len_segmentation_files = len(segmentation_files)\n",
    "\n",
    "if len_outfiles != len_segmentation_files:\n",
    "    print('The length of the outfiles and the segmentation files does not match')\n",
    "    print(f'len_outfiles: {len_outfiles}')\n",
    "    print(f'len_segmentation_files: {len_segmentation_files}')\n",
    "\n",
    "\n",
    "df_files = pd.DataFrame(columns=['outfile', 'segfile', 'key'])\n",
    "outfiles_df = []\n",
    "segfiles_df = []\n",
    "keys_df = []\n",
    "\n",
    "for i in range(min([len_outfiles, len_segmentation_files])):\n",
    "    key = outfiles_keys[i]\n",
    "    outfile = outfiles[i]\n",
    "    segfile = [f for f in segmentation_files if key in f][0]\n",
    "    # print(f'Working on {key}')\n",
    "    # print(f'Outfile: {outfile}')\n",
    "    # print(f'Segfile: {segfile}')\n",
    "\n",
    "    outfiles_df.append(outfile)\n",
    "    segfiles_df.append(segfile)\n",
    "    keys_df.append(key)\n",
    "\n",
    "df_files['outfile'] = outfiles_df\n",
    "df_files['segfile'] = segfiles_df\n",
    "df_files['key'] = keys_df\n",
    "\n",
    "df_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files.to_csv('../../../data/final_filelist_to_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfiles_keys = [f.split('_full')[0] for f in os.listdir(f'../../../data/cluster/output_sam/') if 'full' in f and 'T' in f]\n",
    "\n",
    "outfiles_keys.sort()\n",
    "\n",
    "outfiles = os.listdir('../../../data/cluster/output_sam')\n",
    "outfiles = [f'../../../data/cluster/output_sam/{f}' for f in outfiles if 'full' in f and 'T' in f]\n",
    "outfiles.sort() \n",
    "\n",
    "segmentation_path = '/projekt_agmwend/home_rad/Joshua/Mueller_et_al_2024/data/segmented_data/'\n",
    "segmentation_files = [os.path.join(segmentation_path, f) for f in os.listdir(segmentation_path)]\n",
    "segmentation_files.sort()\n",
    "\n",
    "### compare the length\n",
    "len_outfiles = len(outfiles)\n",
    "len_segmentation_files = len(segmentation_files)\n",
    "\n",
    "if len_outfiles != len_segmentation_files:\n",
    "    print('The length of the outfiles and the segmentation files does not match')\n",
    "    print(f'len_outfiles: {len_outfiles}')\n",
    "    print(f'len_segmentation_files: {len_segmentation_files}')\n",
    "\n",
    "\n",
    "df_files = pd.DataFrame(columns=['outfile', 'segfile', 'key'])\n",
    "outfiles_df = []\n",
    "segfiles_df = []\n",
    "keys_df = []\n",
    "\n",
    "for i in range(min([len_outfiles, len_segmentation_files])):\n",
    "    key = outfiles_keys[i]\n",
    "    outfile = outfiles[i]\n",
    "    segfile = [f for f in segmentation_files if key in f][0]\n",
    "    # print(f'Working on {key}')\n",
    "    # print(f'Outfile: {outfile}')\n",
    "    # print(f'Segfile: {segfile}')\n",
    "\n",
    "    outfiles_df.append(outfile)\n",
    "    segfiles_df.append(segfile)\n",
    "    keys_df.append(key)\n",
    "\n",
    "df_files['outfile'] = outfiles_df\n",
    "df_files['segfile'] = segfiles_df\n",
    "df_files['key'] = keys_df\n",
    "\n",
    "df_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_list = []\n",
    "# ds_full_list = []\n",
    "\n",
    "\n",
    "# for index, row in tqdm(df_files.iterrows(), total=df_files.shape[0]):\n",
    "#     full_file = row['outfile']\n",
    "#     segment_file = row['segfile']\n",
    "\n",
    "#     ds_full = xr.open_dataset(full_file)\n",
    "#     ds_full['lat'] = ds_full['lat'].where(ds_full['lat'] != 0)\n",
    "#     ds_full['lon'] = ds_full['lon'].where(ds_full['lon'] != 0)\n",
    "#     ds_segment = xr.open_dataset(segment_file)\n",
    "#     start_time = full_file.split('/')[-1].split('.nc')[0].split('_')[0]\n",
    "#     end_time = full_file.split('/')[-1].split('.nc')[0].split('_')[1]\n",
    "#     date_range = pd.date_range(start=start_time, end=end_time, periods=ds_full.x.size)\n",
    "#     date = pd.to_datetime(start_time).strftime('%Y-%m-%d')\n",
    "#     if date == '2022-03-20' or date == '2022-03-21':\n",
    "#         continue\n",
    "#     N = ds_segment['segment'].size\n",
    "#     date_array = np.array([date for _ in range(N)])\n",
    "\n",
    "#     ds_segment['segment_date'] = ('segment', date_array)\n",
    "#     ds_full['time'] = ('x', date_range)\n",
    "\n",
    "#     h = histogram(ds_full['smoothed_prediction'].isel(y=slice(635//2-150, 635//2+150)), bins=[[.5, 1.5, 2.5, 3.5, 4.5]], dim=['y'])\n",
    "\n",
    "#     track_lat = ds_full['lat'].mean(dim='y')#isel(y=slice(635//2-150, 635//2+150))\n",
    "#     track_lon = ds_full['lon'].mean(dim='y')#isel(y=slice(635//2-150, 635//2+150))\n",
    "\n",
    "#     ### fill the nan values with the mean between the two nearest values\n",
    "\n",
    "#     track_lat = track_lat.where(~track_lat.isnull(), other=0)\n",
    "#     track_lon = track_lon.where(~track_lon.isnull(), other=0)\n",
    "\n",
    "#     print(date)\n",
    "\n",
    "#     modis_amsr_sic = SIC.sel(time=date)['z']\n",
    "\n",
    "#     modis_amsr_sic_lat, modis_amsr_sic_lon = np.meshgrid(modis_amsr_sic.y.values, modis_amsr_sic.x.values)\n",
    "\n",
    "#     modis_amsr_sic_lat = np.radians(modis_amsr_sic_lat.flatten())\n",
    "#     modis_amsr_sic_lon = np.radians(modis_amsr_sic_lon.flatten())\n",
    "\n",
    "#     tree = BallTree(np.array([modis_amsr_sic_lat, modis_amsr_sic_lon]).T, metric='haversine')\n",
    "\n",
    "#     dist, ind = tree.query(np.array([np.radians(track_lat.values), np.radians(track_lon.values)]).T, k=1)\n",
    "#     dist *= 6357\n",
    "#     good_ind = dist < 1\n",
    "\n",
    "#     closest_modis_amsr_sic = modis_amsr_sic.values.flatten()[ind]\n",
    "#     closest_modis_amsr_sic = np.array(closest_modis_amsr_sic).flatten()\n",
    "#     dist = np.array(dist).flatten()\n",
    "\n",
    "\n",
    "#     ds_sic = xr.Dataset(\n",
    "#         data_vars=dict(\n",
    "#             counts=(('time', 'class_bin'), h.values),\n",
    "#             sic=(('time'), closest_modis_amsr_sic),\n",
    "#             distance=(('time'), dist),\n",
    "#         ),\n",
    "#         coords=dict(\n",
    "#             time=ds_full['time'].values,\n",
    "#             class_bin=[1, 2, 3, 4],\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "#     ds_full_list.append(ds_sic)\n",
    "#     ds_list.append(ds_segment)\n",
    "    \n",
    "\n",
    "# ds = xr.concat(ds_list, dim='segment')\n",
    "# ds_sic = xr.concat(ds_full_list, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list = []\n",
    "ds_full_list = []\n",
    "\n",
    "\n",
    "for index, row in tqdm(df_files.iterrows(), total=df_files.shape[0]):\n",
    "    full_file = row['outfile']\n",
    "    segment_file = row['segfile']\n",
    "\n",
    "    ds_full = xr.open_dataset(full_file)\n",
    "    ds_full['lat'] = ds_full['lat'].where(ds_full['lat'] != 0)\n",
    "    ds_full['lon'] = ds_full['lon'].where(ds_full['lon'] != 0)\n",
    "    ds_segment = xr.open_dataset(segment_file)\n",
    "    start_time = full_file.split('/')[-1].split('.nc')[0].split('_')[0]\n",
    "    end_time = full_file.split('/')[-1].split('.nc')[0].split('_')[1]\n",
    "    date_range = pd.date_range(start=start_time, end=end_time, periods=ds_full.x.size)\n",
    "    date = pd.to_datetime(start_time).strftime('%Y-%m-%d')\n",
    "    if date == '2022-03-20' or date == '2022-03-21':\n",
    "        continue\n",
    "    N = ds_segment['segment'].size\n",
    "    date_array = np.array([date for _ in range(N)])\n",
    "\n",
    "    ds_segment['segment_date'] = ('segment', date_array)\n",
    "    ds_full['time'] = ('x', date_range)\n",
    "\n",
    "    h = histogram(ds_full['smoothed_prediction'].isel(y=slice(635//2-150, 635//2+150)), bins=[[.5, 1.5, 2.5, 3.5, 4.5]], dim=['y'])\n",
    "\n",
    "    track_lat = ds_full['lat'].mean(dim='y')#isel(y=slice(635//2-150, 635//2+150))\n",
    "    track_lon = ds_full['lon'].mean(dim='y')#isel(y=slice(635//2-150, 635//2+150))\n",
    "\n",
    "    ### fill the nan values with the mean between the two nearest values\n",
    "\n",
    "    track_lat = track_lat.where(~track_lat.isnull(), other=0)\n",
    "    track_lon = track_lon.where(~track_lon.isnull(), other=0)\n",
    "\n",
    "    print(date)\n",
    "\n",
    "    modis_amsr_sic = SIC.sel(time=date)['z']\n",
    "\n",
    "    modis_amsr_sic_sel = modis_amsr_sic.sel(\n",
    "        x=track_lon.values,\n",
    "        y=track_lat.values,\n",
    "        method='nearest'\n",
    "    )\n",
    "\n",
    "    ds_sic = xr.Dataset(\n",
    "        data_vars=dict(\n",
    "            counts=(('time', 'class_bin'), h.values),\n",
    "            sic=(('time'), np.diag(modis_amsr_sic_sel.values)),\n",
    "            #distance=(('time'), dist),\n",
    "        ),\n",
    "        coords=dict(\n",
    "            time=ds_full['time'].values,\n",
    "            class_bin=[1, 2, 3, 4],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    ds_full_list.append(ds_sic)\n",
    "    ds_list.append(ds_segment)\n",
    "    \n",
    "\n",
    "ds = xr.concat(ds_list, dim='segment')\n",
    "ds_sic = xr.concat(ds_full_list, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 100 - (h / 3).isel(smoothed_prediction_bin=[0,1]).sum(dim='smoothed_prediction_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.diag(modis_amsr_sic_sel))\n",
    "\n",
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse = 150\n",
    "ds_sic_coarsen = ds_sic.coarsen(time=coarse, boundary='trim').mean()\n",
    "\n",
    "velox_sic = ds_sic_coarsen['counts'].sel(class_bin=[3, 4]).sum(dim='class_bin') / 300 * 100\n",
    "modis_amsr_sic = ds_sic_coarsen['sic'] \n",
    "\n",
    "dupl_mask = ~modis_amsr_sic.indexes['time'].duplicated()\n",
    "modis_amsr_sic = modis_amsr_sic[dupl_mask]\n",
    "velox_sic = velox_sic[dupl_mask]\n",
    "\n",
    "velox_sic = velox_sic[modis_amsr_sic <= 100]\n",
    "modis_amsr_sic = modis_amsr_sic[modis_amsr_sic <= 100]\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, root_mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(modis_amsr_sic, velox_sic))\n",
    "mae = mean_absolute_error(modis_amsr_sic, velox_sic)\n",
    "bias = np.mean(velox_sic - modis_amsr_sic).values\n",
    "\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'Bias: {bias}')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(2, 2))\n",
    "\n",
    "ax.scatter(modis_amsr_sic, velox_sic, s=1, c='k')\n",
    "ax.plot([0, 100], [0, 100], 'r--')\n",
    "ax.set_xlabel('MODIS/AMSR SIC')\n",
    "ax.set_ylabel('VELOX SIC')\n",
    "ax.set_xlim([0, 100])\n",
    "ax.set_ylim([0, 100])\n",
    "\n",
    "ax.text(0.05, 0.95, f'RMSE: {rmse:.2f}\\nMAE: {mae:.2f}\\nBias: {bias:.2f}', transform=ax.transAxes, ha='left', va='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df_files['key'].values)\n",
    "\n",
    "fig, ax = plt.subplots(N, 1, figsize=(12, 2 * N))\n",
    "\n",
    "for i, slice_key in enumerate(df_files['key'].values):\n",
    "    print(i)\n",
    "\n",
    "    time_slice = slice(slice_key.split('_')[0], slice_key.split('_')[1])\n",
    "    print(time_slice)\n",
    "    try:\n",
    "        (100 - (ds_sic_coarsen.counts.sel(time=time_slice) / 3).isel(class_bin=[0, 1]).sum(dim='class_bin')).plot(ax=ax[i], c='blue')\n",
    "        ds_sic.sic.sel(time=time_slice).plot(ax=ax[i], color='k', lw=1)\n",
    "\n",
    "        vel_sic = ds_sic.where(ds_sic['distance'] < 1, drop=True)['counts'].sel(time=time_slice, class_bin=[3, 4]).sum(dim='class_bin') / 300 * 100 \n",
    "        mod_sic = ds_sic.where(ds_sic['distance'] < 1, drop=True)['sic'].sel(time=time_slice)\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(mod_sic, vel_sic))\n",
    "        ax[i].set_title(f'{time_slice} - RMSE: {rmse:.2f}')\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3.15, 2.7))\n",
    "cc = 0\n",
    "\n",
    "legend = []\n",
    "legend_labels = ['Open-water', 'Ice-water mix', 'Thin ice', 'Snow-covered ice']\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size' : 8,\n",
    "    'axes.labelsize' : 8,\n",
    "    'axes.titlesize' : 8,\n",
    "    'xtick.labelsize' : 6,\n",
    "    'ytick.labelsize' : 6,\n",
    "    'legend.fontsize' : 6\n",
    "    })\n",
    "\n",
    "colors = np.array([[0.10588235, 0.61960784, 0.46666667, 1.],\n",
    "                [0.45882353, 0.43921569, 0.70196078, 1.],\n",
    "                [0.4       , 0.4       , 0.4       , 1.],\n",
    "                [0.90196078, 0.67058824, 0.00784314, 1.],\n",
    "])\n",
    "\n",
    "for i in range(4):\n",
    "    ice_areas = ds['segment_size'][ds.segment_label == i+1].values * 100\n",
    "\n",
    "    print(i+1)\n",
    "\n",
    "    N = ice_areas.sum() * 100\n",
    "\n",
    "    #h = ax.hist(ice_areas, bins=np.logspace(1, 6, 15), alpha=.5, histtype='step', density=True)\n",
    "\n",
    "    h = np.histogram(ice_areas, bins=np.logspace(1, 7, 15), density=True)\n",
    "\n",
    "    bin_centers = np.sqrt(h[1][:-1] * h[1][1:])\n",
    "    x = np.log10(bin_centers)\n",
    "    y = np.log10(h[0] * N / 1e5) \n",
    "\n",
    "    mask = np.isfinite(x) & np.isfinite(y)\n",
    "\n",
    "    x = x[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "\n",
    "    ax.scatter(bin_centers, h[0] * N / 1e5, s=30, edgecolor='k', c=colors[i])\n",
    "\n",
    "    from scipy.optimize import curve_fit\n",
    "\n",
    "    def func(x, a, b):\n",
    "        return a * x + b\n",
    "\n",
    "\n",
    "\n",
    "    popt, pcov = curve_fit(func, x, y)\n",
    "\n",
    "    #ax.scatter(x, y, s=30, edgecolor='k')\n",
    "\n",
    "    a = popt[0]\n",
    "    b = 10 ** popt[1]\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "    ### nicely print the results\n",
    "\n",
    "    print(f'N_{i+1} = {b:.2f} * x^{a:.2f} \\t R² = {r_value**2:.4f}, std_err = {std_err:.4f}')\n",
    "    \n",
    "\n",
    "    xx = np.logspace(3, 7, 100)\n",
    "\n",
    "    ax.plot(xx, b * xx ** a, c=colors[i])\n",
    "\n",
    "    print(a, b)\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    SSD = \"SSD\"\n",
    "    SEG = \"SEG\"\n",
    "\n",
    "    ax.text(\n",
    "        0.65,\n",
    "        cc+.79,\n",
    "        f'$N_\\mathrm{{SSD}} \\sim (x_\\mathrm{{SEG}})^{{{a:.2f}}} $',\n",
    "        fontsize=6,\n",
    "        transform=ax.transAxes,\n",
    "        color=colors[i],\n",
    "    )\n",
    "    cc += .05\n",
    "\n",
    "    ax.set_xlim(1e1, 1e8)\n",
    "    ax.set_ylim(1e-5, 1e3)\n",
    "\n",
    "    ax.set_xlabel('$x_\\mathrm{SEG}$ (m²)')\n",
    "    ax.set_ylabel('$N_\\mathrm{SSD}$ (km$^{-2}$)')\n",
    "\n",
    "    ### add a rectangle to the upper right corner in the background\n",
    "\n",
    "    ax.add_patch(plt.Rectangle((0.6, 0.8), 0.4, 0.2, fill=True, color='w', alpha=0.5, transform=ax.transAxes, zorder=1))\n",
    "\n",
    "\n",
    "    #ax.set_title('Segment area distribution')\n",
    "\n",
    "    legend.append(ax.scatter([], [], s=30, edgecolor='k', c=colors[i]),)\n",
    "\n",
    "    #legend_labels[i] += f' $y \\sim x^{{{a:.2f}}} $'\n",
    "\n",
    "ax.legend(legend, legend_labels, \n",
    "          loc='lower left', \n",
    "          fontsize=8,\n",
    "          frameon=False)\n",
    "ax.set_aspect('equal')\n",
    "ax.axes.grid(True, linestyle='-', linewidth=0.5, which='major')\n",
    "ax.spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "plt.savefig('../../../plots/segment_area_distribution_andre_v1.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = ds.segment_size.values.flatten()\n",
    "area_labels = ds.segment_label.values.flatten()\n",
    "ice_areas = areas[(area_labels == 3)|(area_labels == 4)]\n",
    "ice_areas = areas\n",
    "\n",
    "#fig, ax = plt.subplots(1, 1, figsize=(10, 2), sharex=True)\n",
    "#h = ax.hist(ice_areas, bins=np.logspace(1, 6, 15), alpha=.5, histtype='step', density=True)\n",
    "#plt.close()\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "bin_centers = np.sqrt(h[1][:-1] * h[1][1:])\n",
    "x = np.log10(bin_centers)\n",
    "y = np.log10(h[0] * 31.75) \n",
    "\n",
    "mask = np.isfinite(x) & np.isfinite(y)\n",
    "\n",
    "x = x[mask]\n",
    "y = y[mask]\n",
    "\n",
    "#fig, ax = plt.subplots(1, 2, figsize=(4, 2))\n",
    "\n",
    "#ax[0].scatter(x, y, s=30, edgecolor='k')\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "popt, pcov = curve_fit(func, x, y)\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "# ax[0].plot(x, func(x, *popt), 'r')\n",
    "\n",
    "# ax[0].text(0.45, 0.9, f'y = {popt[0]:.2f}x + {popt[1]:.2f}', fontsize=6, transform=ax[0].transAxes)\n",
    "\n",
    "# R2 = 1 - np.sum((y - func(x, *popt))**2) / np.sum((y - np.mean(y))**2)\n",
    "\n",
    "# ax[0].text(0.45, 0.8, f'R² = {R2:.4f}', fontsize=6, transform=ax[0].transAxes)\n",
    "\n",
    "# ax[0].set_xlim(1, 6)\n",
    "# ax[0].set_xticks(np.arange(1, 7))\n",
    "\n",
    "# ax[0].set_ylim(-6, 0)\n",
    "# ax[0].set_yticks(np.arange(-6, 1))\n",
    "\n",
    "# ### now plot the power law fit\n",
    "\n",
    "# x = bin_centers\n",
    "# y = h[0] * 31.75\n",
    "\n",
    "# #ax[1].scatter(x, y, s=30, edgecolor='k')\n",
    "\n",
    "# a = popt[0]\n",
    "# b = 10 ** popt[1]\n",
    "\n",
    "# xx = np.logspace(1, 6, 100)\n",
    "\n",
    "# ax[1].plot(xx, b * xx ** a, 'r')\n",
    "\n",
    "# print(a, b)\n",
    "\n",
    "# ax[1].set_xscale('log')\n",
    "# ax[1].set_yscale('log')\n",
    "\n",
    "# ax[1].set_xlim(10, 1e6)\n",
    "# ax[1].set_ylim(1e-6, 1)\n",
    "\n",
    "# ax[1].text(\n",
    "#     0.45,\n",
    "#     0.9,\n",
    "#     f'$y \\sim x^{{{a:.2f}}} $',\n",
    "#     fontsize=6,\n",
    "#     transform=ax[1].transAxes,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(ds['segment_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_segment_file = '/projekt_agmwend/home_rad/Joshua/Mueller_et_al_2024/data/segmented_data_with_edge_distance_nadir_v1.nc'\n",
    "\n",
    "if os.path.exists(ds_segment_file):\n",
    "    ds = xr.open_dataset(ds_segment_file)\n",
    "else:\n",
    "    ds['segment_edge_dist'] = xr.DataArray(np.zeros(ds.segment_lat.size) * np.nan, dims=('segment'))\n",
    "    ds['segment_sic'] = xr.DataArray(np.zeros(ds.segment_lat.size) * np.nan, dims=('segment'))\n",
    "    segment_edge_dist = np.zeros(ds.segment_lat.size)  ### in km\n",
    "    selected_edge_points = np.zeros((ds.segment_lat.size, 2))\n",
    "\n",
    "    ds_miz_edge_full = SIC.where((SIC['z'] > 9) & (SIC['z'] < 11)).stack(feature=('time','x', 'y')).dropna('feature')\n",
    "    #ds_miz_edge = SIC.where((SIC['z'] > 9) & (SIC['z'] < 11)).mean(dim='time').stack(feature=('x', 'y')).dropna('feature')\n",
    "\n",
    "    for i, seg in tqdm(enumerate(ds.segment), total=ds.segment.size):\n",
    "        # if ds.segment_size.isel(segment=i) < 100:\n",
    "        #     continue\n",
    "        lat = ds.segment_lat.isel(segment=i)\n",
    "        lon = ds.segment_lon.isel(segment=i)\n",
    "\n",
    "        date = ds.segment_date.isel(segment=i)#.dt.strftime('%Y-%m-%d')\n",
    "        ds_miz_edge = ds_miz_edge_full.sel(time=date)\n",
    "\n",
    "        miz_lats = ds_miz_edge.y.values\n",
    "        miz_lons = ds_miz_edge.x.values\n",
    "\n",
    "        if np.isnan(lat) or np.isnan(lon):\n",
    "            continue\n",
    "\n",
    "        haversine_dist = haversine_sklearn(lat, lon, miz_lats, miz_lons).flatten()\n",
    "        \n",
    "        min_dist_index = haversine_dist.argmin()\n",
    "\n",
    "        min_dist_lon = miz_lons[min_dist_index]\n",
    "        min_dist_lat = miz_lats[min_dist_index]\n",
    "\n",
    "        edge_dist = haversine_dist[min_dist_index]\n",
    "\n",
    "        ds['segment_edge_dist'][i] = edge_dist\n",
    "        ds['segment_sic'][i] = SIC.sel(x=lon, method='nearest').sel(y=lat, method='nearest').sel(time=date).z.values\n",
    "        segment_edge_dist[i] = edge_dist\n",
    "\n",
    "        selected_edge_points[i, 0] = min_dist_lon\n",
    "        selected_edge_points[i, 1] = min_dist_lat\n",
    "\n",
    "    ds['segment_edge_dist'] = xr.DataArray(segment_edge_dist, dims=('segment')) \n",
    "    ds.to_netcdf('../../../data/segmented_data_with_edge_distance_nadir_v1.nc', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_training = xr.open_dataset('../../../data/training.nc')\n",
    "train_lat = ds_training.lat.values\n",
    "train_lon = ds_training.lon.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.patheffects as path_effects\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "SIC = xr.open_dataset('/projekt_agmwend/home_rad/Joshua/HALO-AC3_unified_data/amsr_modis_sic.nc')\n",
    "\n",
    "# projection center point\n",
    "lon0 = 0\n",
    "lat0 = 78\n",
    "\n",
    "plt.rcParams['font.size'] = 8\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4.15, 4.15))\n",
    "\n",
    "m = Basemap(projection='stere', resolution='h',\n",
    "        lat_0=lat0, lon_0=lon0,  lat_ts=lat0, width=1400000, height=1100000, ax=ax)\n",
    "\n",
    "m.drawmeridians(np.arange(0, 360, 10), labels=[0,0,0,1])  # left, right, top, bottom\n",
    "m.drawparallels(np.arange(0, 90, 5), labels=[1,0,0,0])\n",
    "m.shadedrelief()\n",
    "\n",
    "X, Y = np.meshgrid(SIC.x.values, SIC.y.values)\n",
    "\n",
    "X, Y = m(X, Y)  \n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "data = SIC.mean(dim='time')['z']\n",
    "data = data.where((data != 0) & (data < 100))\n",
    "\n",
    "im = m.contourf(X, Y, data, cmap=cmocean.cm.ice, vmin=10, vmax=100, levels=10, alpha=1,)\n",
    "\n",
    "cs = m.contour(X, Y, data, levels=[10], colors='dimgray', linewidths=1)\n",
    "ax.clabel(cs, inline=1, fontsize=6)\n",
    "handles_10, labels_10 = cs.legend_elements()\n",
    "\n",
    "\n",
    "cs = m.contour(X, Y, data, levels=[90], colors='darkgray', linewidths=1, linestyles='dashed')\n",
    "handles_80, labels_80 = cs.legend_elements()\n",
    "#ax.clabel(cs, inline=1, fontsize=6)\n",
    "\n",
    "m.drawcoastlines(linewidth=0.5)\n",
    "\n",
    "lons = ds.segment_lon.values.flatten()\n",
    "lats = ds.segment_lat.values.flatten()\n",
    "\n",
    "x, y = m(lons, lats)\n",
    "\n",
    "#m.scatter(x, y, c=ds.segment_label.values.flatten(), cmap=cmap, norm=norm, s=2, zorder=100)\n",
    "im1 = m.scatter(x, y, c='gold', s=1, zorder=1, edgecolor='k', lw=.05)\n",
    "\n",
    "\n",
    "cbar = m.colorbar(im, location='right', pad=\"10%\", label='Sea Ice Concentration (%)')\n",
    "cbar.ax.yaxis.set_ticks_position('right')\n",
    "\n",
    "legend = []\n",
    "\n",
    "legend.append(ax.scatter([], [], s=30, edgecolor='k', c='gold'),)\n",
    "legend_labels = ['Open Water', 'Ice Water Mix', 'Thin Ice', 'Snow-Covered','Training data', '10% SIC', '90% SIC', ]\n",
    "legend_labels = ['MIZ dataset','Training data', '10% SIC', '90% SIC',]\n",
    "\n",
    "# for i in range(4):\n",
    "#     legend.append(ax.scatter([], [], s=30, edgecolor='k', c=colors[i]),)\n",
    "\n",
    "#     #legend_labels[i] += f' $y \\sim x^{{{a:.2f}}} $'\n",
    "\n",
    "x, y = m(train_lon, train_lat)\n",
    "\n",
    "im = m.scatter(x, y, c='violet', s=30, zorder=10, marker='*', edgecolor='k', lw=.1)\n",
    "legend.append(im)\n",
    "legend.append(handles_10[0])\n",
    "legend.append(handles_80[0])\n",
    "\n",
    "\n",
    "\n",
    "y, x = [78.22300973348118], [15.655859070165498]\n",
    "x, y = m(x, y)\n",
    "\n",
    "m.scatter(x, y, c='r', s=30, zorder=100, marker='*', edgecolor='k', lw=.1)\n",
    "\n",
    "text = ax.text(x[0]+1, y[0]+0.3, 'Longyearbyen', fontsize=6, color='r', ha='left', va='bottom', transform=ax.transData)\n",
    "text.set_path_effects([path_effects.Stroke(linewidth=1, foreground='white'), path_effects.Normal()])\n",
    "\n",
    "\n",
    "ds_tracks = xr.open_dataset('/projekt_agmwend/home_rad/Joshua/HALO-AC3_unified_data/unified_gps_new.nc')\n",
    "ds_tracks.coarsen(time=100, boundary='trim').mean()\n",
    "\n",
    "x, y = m(ds_tracks.lon.values, ds_tracks.lat.values)\n",
    "\n",
    "im = m.plot(x, y, lw=.1, c='r', alpha=0.75)\n",
    "legend.append(im[0])\n",
    "legend_labels.append('HALO track')\n",
    "\n",
    "ax.legend(legend, legend_labels, \n",
    "          loc='upper left', \n",
    "          fontsize=6,\n",
    "          frameon=True,\n",
    "          ).set_zorder(101)\n",
    "\n",
    "ax.xaxis.set_label_position('bottom')\n",
    "ax.yaxis.set_label_position('right')\n",
    "\n",
    "\n",
    "figx = fig.supxlabel('Longitude')\n",
    "figy = fig.supylabel('Latitude')\n",
    "\n",
    "figx.set_position([0.5, 0.15])\n",
    "figy.set_position([0.04, 0.52])\n",
    "\n",
    "plt.savefig('../../../plots/make_plots_map_v8_andre.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIC_sel = SIC\n",
    "# ds_miz_edge = SIC_sel.where((SIC_sel['z'] > 9) & (SIC_sel['z'] < 11))\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(2, 1, figsize=(3.15, 6))\n",
    "\n",
    "# ds_miz_edge.mean(dim='time').z.plot.imshow(cmap='gray', x='x', add_colorbar=False, ax=ax[0])\n",
    "# im = ax[0].scatter(ds.segment_lon, ds.segment_lat, c=ds.segment_label, cmap=cmap, s=np.log10(ds.segment_size)**2, edgecolors='k', linewidths=0, alpha=.7)\n",
    "# cbar = plt.colorbar(im, label='Surface type')\n",
    "# cbar.ax.set_yticks([0.5, 1.5, 2.5, 3.5])\n",
    "# cbar.ax.set_yticklabels(['Open Water', 'Ice-Water Mix', 'Thin Ice', 'Snow-Covered Ice'])\n",
    "# ax[0].set_xlim(-20, 20)\n",
    "# ax[0].set_ylim(75., 82.)\n",
    "\n",
    "# plt.scatter(selected_edge_points[:, 0], selected_edge_points[:, 1], c='r', s=10, label='Selected Edge Points')\n",
    "\n",
    "# ds_miz_edge = SIC_sel.where((SIC_sel['z'] > 9) & (SIC_sel['z'] < 11)).mean(dim='time')\n",
    "\n",
    "# ds_miz_edge.z.plot.imshow(cmap='gray', x='x', add_colorbar=False, ax=ax[1])\n",
    "# im = ax[1].scatter(ds.segment_lon, ds.segment_lat, c=ds.segment_edge_dist, cmap='viridis', s=np.log10(ds.segment_size)**2, edgecolors='k', linewidths=0, alpha=.7)\n",
    "# plt.colorbar(im, label='Distance to Edge [km]')\n",
    "# ax[1].set_xlim(-20, 20)\n",
    "# ax[1].set_ylim(75., 82.)\n",
    "\n",
    "# ax[1].scatter(selected_edge_points[:, 0], selected_edge_points[:, 1], c='r', s=10, label='Selected Edge Points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(3, 2))\n",
    "\n",
    "# Create a scatter plot\n",
    "im = ax.scatter(ds['segment_size'] / 1e4, \n",
    "                ds['segment_T'], \n",
    "                c=ds['segment_label'], \n",
    "                cmap=cmap, \n",
    "                norm=norm,\n",
    "                s=3, \n",
    "                edgecolors='none', \n",
    "                linewidth=0.2, \n",
    "                alpha=.8)\n",
    "\n",
    "# Set the x-axis to a logarithmic scale\n",
    "ax.set_xscale('log')\n",
    "# Hide the top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Label the axes\n",
    "ax.set_xlabel('Area (km²)')\n",
    "ax.set_ylabel('Mean $T_\\mathrm{skin}$ (°C)')\n",
    "\n",
    "# Create a divider for the axis to append a colorbar\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size='7.5%', pad=0.05)\n",
    "cax.grid(False)\n",
    "\n",
    "# Add a colorbar to the plot with discrete levels\n",
    "cbar = fig.colorbar(im, cax=cax, orientation='vertical', ticks=[1.5, 2.5, 3.5, 4.5])\n",
    "#cbar.set_label('Surface type')\n",
    "cbar.ax.set_yticklabels(['Open\\nWater', 'Ice\\nWater\\nMix', 'Thin\\nIce', 'Snow\\nCovered\\nIce'])\n",
    "cbar.ax.yaxis.set_tick_params(width=0, length=0)\n",
    "cbar.ax.yaxis.set_ticks_position('none')\n",
    "cbar.ax.spines[['top', 'right', 'bottom', 'left']].set_visible(False)\n",
    "cbar.ax.set_frame_on(False)\n",
    "\n",
    "dsgp_1 = ds.groupby('segment_label').mean()\n",
    "\n",
    "ax.scatter(dsgp_1['segment_size'] / 1e4,\n",
    "              dsgp_1['segment_T'],\n",
    "              c=np.arange(4),\n",
    "              cmap=cmap,\n",
    "              s=10,\n",
    "              edgecolors='black',\n",
    "              linewidth=0.5,\n",
    "              marker='o',\n",
    "              zorder=10) \n",
    "\n",
    "### add the error bars\n",
    "ax.xaxis.get_minor_locator().set_params(numticks=99, subs=[.2, .4, .6, .8])\n",
    "ax.set_xticks([1e-3, 1e-2, 1e-1, 1e0, 1e1])\n",
    "ax.set_xlim([1e-3, 1e1])\n",
    "\n",
    "plt.savefig('plot_segstats_scatter_tskin_size.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('plot_segstats_scatter_tskin_size.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_group_mean = ds.groupby('segment_label').median()\n",
    "label_group_std = ds.groupby('segment_label').std()\n",
    "\n",
    "\n",
    "x = ds['segment_edge_dist'].values\n",
    "y = ds['segment_size'].values\n",
    "c = ds['segment_label'].values\n",
    "T = ds['segment_T'].values\n",
    "std = ds['segment_std'].values\n",
    "\n",
    "all_nan = np.isnan(x) | np.isnan(y) | np.isnan(c) | np.isnan(T) | np.isnan(std)\n",
    "\n",
    "x = x[~all_nan]\n",
    "y = y[~all_nan]\n",
    "c = c[~all_nan]\n",
    "T = T[~all_nan]\n",
    "std = std[~all_nan]\n",
    "\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm, LogNorm\n",
    "\n",
    "fig, ax = plt.subplots(4, 2, figsize=(8, 8), sharex=True)\n",
    "\n",
    "titles = ['Open Water', 'Ice Water Mix', 'Snow covered', 'Thin Ice']\n",
    "\n",
    "for i in range(4):\n",
    "    #ax[i,0].scatter(x[c == i + 1], y[c == i + 1], s=1, color=colors[i])\n",
    "    ax[i,0].set_yscale('log')\n",
    "    ax[i,0].hist2d(x[c == i + 1], y[c == i + 1], bins=(np.linspace(0, 150, 30), np.logspace(0, 6, 30)), cmap='viridis', norm=LogNorm())\n",
    "    #ax[i,1].scatter(x[c == i + 1], T[c == i + 1], s=1, color=colors[i])\n",
    "    ax[i,1].hist2d(x[c == i + 1], T[c == i + 1], bins=30, cmap='viridis', norm=LogNorm())\n",
    "    ax[i,0].set_ylabel(f'{titles[i]}\\n area (m²)')\n",
    "    ax[i,1].set_ylabel(f'{titles[i]}\\n $T_\\mathrm{{skin}}$ (°C)')\n",
    "    ax[i,1].yaxis.tick_right()\n",
    "\n",
    "ax[0,0].xaxis.set_ticks_position('top')\n",
    "ax[0,0].xaxis.set_label_position('top')\n",
    "ax[0,1].xaxis.set_ticks_position('top')\n",
    "ax[0,1].xaxis.set_label_position('top')\n",
    "ax[0,0].set_xlabel('Distance to MIZ edge (km)')\n",
    "ax[0,1].set_xlabel('Distance to MIZ edge (km)')\n",
    "\n",
    "cb = fig.colorbar(ax[0,0].collections[0], ax=ax, orientation='horizontal', label='Count', shrink=0.3, pad=0.05, location='bottom')\n",
    "\n",
    "plt.savefig('plot_segstats_hist2d_all_types_viridis.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('plot_segstats_hist2d_all_types_viridis.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axd = plt.subplot_mosaic(\n",
    "    \"\"\"A\n",
    "    B\n",
    "    C\"\"\", \n",
    "    figsize=(4, 7),\n",
    "    gridspec_kw={\n",
    "      'hspace': 0.3,\n",
    "      'wspace': 0.3\n",
    "    },\n",
    "    sharex=True)\n",
    "list_of_ax = [_[1] for _ in axd.items()]\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "range_size = np.logspace(0, 6, 30)\n",
    "range_dist = np.linspace(0, 150, 30)\n",
    "range_temp = np.linspace(-30, 0, 30)\n",
    "range_std  = np.linspace(0, 10, 30)\n",
    "range_ecc  = np.linspace(0, 1, 30)\n",
    "\n",
    "im = axd['A'].hist2d(x, y, bins=(range_dist, range_size), cmap='viridis', norm=LogNorm())\n",
    "axd['A'].set_yscale('log')\n",
    "axd['B'].hist2d(x, T, bins=(range_dist, range_temp), cmap='viridis', norm=LogNorm())\n",
    "axd['C'].hist2d(x, std, bins=(range_dist, range_std), cmap='viridis', norm=LogNorm())\n",
    "\n",
    "#fig.colorbar(h[3], ax=list_of_ax, orientation='vertical', label='Count', ticks=[1, 10, 20, 30, 40, 50], shrink=0.5, pad=0.05)\n",
    "\n",
    "edge_dist_mean = ds.groupby('segment_label').median()['segment_edge_dist']\n",
    "temp_mean = ds.groupby('segment_label').median()['segment_T']\n",
    "size_mean = ds.groupby('segment_label').median()['segment_size']\n",
    "std_mean = ds.groupby('segment_label').median()['segment_std']\n",
    "\n",
    "for i in range(4):\n",
    "    axd['A'].scatter(edge_dist_mean[i], size_mean[i], s=50, color=colors[i], edgecolors='black', linewidth=0.5,alpha=.85, marker='o')\n",
    "    axd['B'].scatter(edge_dist_mean[i], temp_mean[i], s=50, color=colors[i], edgecolors='black', linewidth=0.5,alpha=.85, marker='o')\n",
    "    axd['C'].scatter(edge_dist_mean[i], std_mean[i], s=50, color=colors[i], edgecolors='black', linewidth=0.5, alpha=.85,marker='o')\n",
    "\n",
    "\n",
    "axd['A'].set_ylabel('area (m²)')\n",
    "axd['B'].set_ylabel('$T_\\mathrm{skin}$ (°C)')\n",
    "axd['C'].set_ylabel('$\\sigma\\,T_\\mathrm{skin}$ (°C)')\n",
    "axd['C'].set_xlabel('distance to MIZ edge (km)')\n",
    "\n",
    "\n",
    "plt.savefig('plot_segstats_hist2d_all_vars_to_miz_edge.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('plot_segstats_hist2d_all_vars_to_miz_edge.pdf', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(5, 2), sharey=True)\n",
    "\n",
    "Tmax = np.nanmax(T)\n",
    "Tmin = np.nanmin(T)\n",
    "\n",
    "sizemax = np.log10(np.nanmax(y))\n",
    "sizemin = np.log10(np.nanmin(y))\n",
    "\n",
    "\n",
    "print(Tmax, Tmin, sizemax, sizemin)\n",
    "\n",
    "h = ax[0].hist2d(y, T, bins=(np.logspace(sizemin, sizemax, 30), np.linspace(Tmin, Tmax, 30)), cmap='viridis', norm=LogNorm())\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_xlabel('Area (km²)')\n",
    "ax[0].set_ylabel(r'Mean $T_\\mathrm{skin}$ (°C)')\n",
    "#ax[0].set_xticks([1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3])\n",
    "for i in range(4):\n",
    "    ax[0].scatter(size_mean[i]/1e4, temp_mean[i], s=50, color=colors[i], edgecolors='black', linewidth=0.5,alpha=.85, marker='o')\n",
    "\n",
    "ax[1].hist2d(std, T, bins=(np.linspace(0, 5, 60), np.linspace(-30, 0, 60)) , cmap='viridis', norm=LogNorm())\n",
    "#ax[1].set_xlabel(r'$\\sigma\\,T_\\mathrm{skin}$ (°C)')\n",
    "#ax[1].set_xticks([0, 1, 2, 3, 4, 5])\n",
    "#ax[1].set_yticks([-30, -25, -20, -15, -10, -5, 0])\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    ax[1].scatter(std_mean[i], temp_mean[i], s=50, color=colors[i], edgecolors='black', linewidth=0.5,alpha=.85, marker='o')\n",
    "\n",
    "ax[0].spines[['top', 'right']].set_visible(False)\n",
    "ax[1].spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "cb = fig.colorbar(h[3], ax=ax, orientation='vertical', label='Counts')\n",
    "#cb.set_ticklabels([1, 5, 10, 30, 50, 70])\n",
    "#ax[0].xaxis.get_minor_locator().set_params(numticks=99, subs=[.2, .4, .6, .8])\n",
    "### add the a b label\n",
    "\n",
    "ax[0].text(0, 1.07, 'a', transform=ax[0].transAxes, fontsize=8, fontweight='bold', va='top')\n",
    "ax[1].text(0, 1.07, 'b', transform=ax[1].transAxes, fontsize=8, fontweight='bold', va='top')\n",
    "\n",
    "for i in range(4):\n",
    "    ax[0].scatter(size_mean[i], temp_mean[i], s=50, color=colors[i], edgecolors='black', linewidth=0.5,alpha=.85, marker='o')\n",
    "    ax[1].scatter(std_mean[i], temp_mean[i], s=50, color=colors[i], edgecolors='black', linewidth=0.5,alpha=.85, marker='o')\n",
    "\n",
    "plt.savefig('../../../plots/make_plots_hist2d_tskin_area_sigma_.png', bbox_inches='tight', dpi=300)\n",
    "#plt.savefig('../../plots/plot_segstats_hist2d_tskin_area_sigma_.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "fit_dict = {\n",
    "    'slope' : [],\n",
    "    'intercept' : [],\n",
    "    'r_value' : [],\n",
    "    'p_value' : [],\n",
    "}\n",
    "\n",
    "def power_law_fit(x0, num_bins):\n",
    "\n",
    "    bins = np.logspace(1, 6, num_bins)\n",
    "\n",
    "\n",
    "    counts, bin_edges = np.histogram(x0, bins=bins, density=True)\n",
    "\n",
    "    x = np.log10(np.sqrt(bin_edges[1:] * bin_edges[:-1]))\n",
    "    y = np.log10(counts)\n",
    "\n",
    "\n",
    "    fit_result = linregress(x, y)\n",
    "\n",
    "    return fit_result\n",
    "\n",
    "#ice_areas = areas[(area_labels == 3)|(area_labels == 4)]\n",
    "\n",
    "\n",
    "ice_areas = ds['segment_size'].values\n",
    "#ice_areas = areas\n",
    "\n",
    "num_bin_range = np.arange(10, 20, 1)\n",
    "\n",
    "for num_bins in num_bin_range:\n",
    "\n",
    "    fit_result = power_law_fit(ice_areas, num_bins)\n",
    "\n",
    "    fit_dict['slope'].append(fit_result.slope)\n",
    "    fit_dict['intercept'].append(fit_result.intercept)\n",
    "    fit_dict['r_value'].append(fit_result.rvalue)\n",
    "    fit_dict['p_value'].append(fit_result.pvalue)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 2), sharex=True)\n",
    "\n",
    "ax[0].scatter(num_bin_range, fit_dict['slope'], label='slope')\n",
    "ax[1].scatter(num_bin_range, fit_dict['intercept'], label='intercept')\n",
    "ax[2].scatter(num_bin_range, np.array(fit_dict['r_value'])**2, label='r_value')\n",
    "ax[3].scatter(num_bin_range, fit_dict['p_value'], label='p_value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_number = 16\n",
    "ds_gbed = ds.isel(segment=(ds.segment_label.values==4)).groupby_bins('segment_edge_dist', bins=np.linspace(0, 150, bin_number))\n",
    "\n",
    "\n",
    "def fit_and_plot(x, y, ax, c=None, label=None):\n",
    "    fit_result = linregress(x, y)\n",
    "    color = 'darkred' if c is None else c\n",
    "    ax.scatter(x, y, c=c, label=label)\n",
    "    xx = np.linspace(min(x), max(x), 100)\n",
    "    ax.plot(xx, fit_result.slope * xx + fit_result.intercept, color='black', linestyle='--')\n",
    "    ax.text(.05, .75, f'$R^2$ = {fit_result.rvalue**2:.3f}\\n$p$ = {fit_result.pvalue:.2e}\\n$slope$ = {fit_result.slope:.2e}', transform=ax.transAxes, fontsize=8, va='bottom')                 \n",
    "\n",
    "\n",
    "def power_law_fit(x0, num_bins):\n",
    "    num_bins = 15\n",
    "    x0min = 1\n",
    "    x0max = 7\n",
    "    #x0min = np.log(np.min(x0))\n",
    "    #x0max = np.log(np.max(x0))\n",
    "    bins = np.logspace(x0min, x0max, num_bins)\n",
    "    counts, bin_edges = np.histogram(x0, bins=bins, density=True)\n",
    "\n",
    "    x = np.log10(np.sqrt(bin_edges[1:] * bin_edges[:-1]))\n",
    "    y = np.log10(counts)\n",
    "\n",
    "    inf_mask = np.isinf(y)\n",
    "    x = x[~inf_mask]\n",
    "    y = y[~inf_mask]\n",
    "\n",
    "    N = len(x)\n",
    "    fit_result = linregress(x, y)\n",
    "\n",
    "    return fit_result, N\n",
    "\n",
    "### iterate over the groups and get the size distribution\n",
    "fit_dict = {\n",
    "    'slope' : [],\n",
    "    'intercept' : [],\n",
    "    'r_value' : [],\n",
    "    'p_value' : [],\n",
    "    'edge_dist' : [],\n",
    "    'N' : [],\n",
    "    'T' : [],\n",
    "    'SIC' : [],\n",
    "    'STD' : [],\n",
    "    'slope_err' : [],\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "def area_weighted_mean(x, w):\n",
    "\n",
    "    return np.sum(x * w) / np.sum(w)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i, group in ds_gbed:\n",
    "\n",
    "    edge_dist = group['segment_edge_dist'].values.mean()\n",
    "    ice_areas = group['segment_size'].values\n",
    "    area_labels = group['segment_label'].values\n",
    "    sic = group['segment_sic'].values\n",
    "\n",
    "    ice_area = ice_areas[(area_labels == 3)|(area_labels == 4)]\n",
    "\n",
    "    fit_result, n = power_law_fit(ice_areas, bin_number)\n",
    "\n",
    "    fit_dict['slope'].append(fit_result.slope)\n",
    "    fit_dict['intercept'].append(fit_result.intercept)\n",
    "    fit_dict['r_value'].append(fit_result.rvalue**2)\n",
    "    fit_dict['p_value'].append(fit_result.pvalue)\n",
    "    fit_dict['edge_dist'].append(edge_dist)\n",
    "    fit_dict['N'].append(n)\n",
    "\n",
    "    awm_T = area_weighted_mean(group['segment_T'].values, ice_areas)\n",
    "    awm_SIC = area_weighted_mean(group['segment_sic'].values, ice_areas)\n",
    "    awm_STD = area_weighted_mean(group['segment_std'].values, ice_areas)\n",
    "\n",
    "    fit_dict['T'].append(awm_T)\n",
    "    fit_dict['SIC'].append(awm_SIC)\n",
    "    fit_dict['STD'].append(awm_STD)\n",
    "\n",
    "    # fit_dict['T'].append(group['segment_T'].mean().values)\n",
    "    # fit_dict['SIC'].append(group['segment_sic'].mean().values)\n",
    "    # fit_dict['STD'].append(group['segment_std'].mean().values)\n",
    "    fit_dict['slope_err'].append(fit_result.stderr)\n",
    "\n",
    "\n",
    "### now let'S see if there's a scaling in miz dependce of the slope \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(6, 5), \n",
    "                       sharex=True, sharey=False,\n",
    "                       gridspec_kw={'hspace': 0.3, 'wspace': 0.3})\n",
    "\n",
    "fit_and_plot(fit_dict['edge_dist'], fit_dict['slope'], ax[0,0], label='slope')\n",
    "fit_and_plot(fit_dict['edge_dist'], fit_dict['intercept'], ax[0,1],label='intercept')\n",
    "fit_and_plot(fit_dict['edge_dist'], fit_dict['T'], ax[1,0])\n",
    "fit_and_plot(fit_dict['edge_dist'], fit_dict['STD'], ax[1,1])\n",
    "\n",
    "\n",
    "ax[0,0].set_xlabel(r'Distance to MIZ edge [km]')\n",
    "ax[0,0].set_ylabel(r'Slope')\n",
    "ax[0,1].set_xlabel(r'Distance to MIZ edge [km]')\n",
    "ax[0,1].set_ylabel(r'Intercept')\n",
    "ax[1,0].set_xlabel(r'Distance to MIZ edge [km]')\n",
    "ax[1,0].set_ylabel(r'Mean $T_\\mathrm{skin}$ [°C]')\n",
    "ax[1,1].set_xlabel(r'Distance to MIZ edge [km]')\n",
    "ax[1,1].set_ylabel(r'Mean $\\sigma T_\\mathrm{skin}$ [°C]')\n",
    "plt.savefig('../../../plots/make_plots_all_vs_distance.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_weighted_mean(x, w):\n",
    "\n",
    "    return np.nansum(x * w) / np.nansum(w)\n",
    "\n",
    "### calc the area weighted mean of T\n",
    "\n",
    "awm = area_weighted_mean(ds['segment_T'].values, ds['segment_size'].values)\n",
    "m = ds['segment_T'].mean().values\n",
    "\n",
    "print(awm, m)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_fit_result = pd.DataFrame(fit_dict)\n",
    "\n",
    "df_fit_result.corr()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, (ax) = plt.subplots(1, 1, figsize=(3.15, 2), sharex=True)\n",
    "\n",
    "\n",
    "im = ax.scatter(fit_dict['edge_dist'], fit_dict['slope'], c='grey', cmap='inferno', edgecolors='k', lw=.5 , vmin=-20, vmax=-5)\n",
    "fit_res = linregress(fit_dict['edge_dist'], fit_dict['slope'])\n",
    "xx = np.linspace(1, 150, 100)\n",
    "ax.plot(xx, fit_res.slope * xx + fit_res.intercept, color='r', linestyle='--', label='linear fit', \n",
    "        lw=2, alpha=0.7)\n",
    "#ax2.set_xlabel('Distance to ice edge (km)')\n",
    "ax.set_ylabel(r'$\\beta$')\n",
    "\n",
    "y_err = ax.errorbar(fit_dict['edge_dist'], fit_dict['slope'], yerr=fit_dict['slope_err'], fmt='none', ecolor='grey', alpha=0.7, capsize=3, capthick=1)\n",
    "\n",
    "\n",
    "r = fit_res.rvalue\n",
    "p = fit_res.pvalue\n",
    "slope = fit_res.slope\n",
    "\n",
    "#ax.text(.05, .8, f'$R^2$ = {r**2:.3f}\\n$p$ = {p:.2e}\\n$slope$ = {slope:.2e}', transform=ax.transAxes, fontsize=8, va='bottom')\n",
    "\n",
    "ax.spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "#ax2.scatter(fit_dict['edge_dist'], fit_dict['STD'], c='grey',  edgecolors='k', lw=.5 ,)\n",
    "#ax2.set_ylabel(r'$\\sigma\\,T_\\mathrm{skin}$ (K)')\n",
    "\n",
    "fit_res = linregress(fit_dict['edge_dist'], fit_dict['STD'])\n",
    "xx = np.linspace(1, 150, 100)##\n",
    "\n",
    "#ax2.plot(xx, fit_res.slope * xx + fit_res.intercept, color='r', linestyle='-', label='y={:.2f}x+{:.2f}'.format(fit_res.slope, fit_res.intercept))\n",
    "\n",
    "ax.set_xlabel('Distance to sea-ice edge (km)')\n",
    "\n",
    "#plt.colorbar(im, label='Mean $T_\\mathrm{skin}$ (°C)')\n",
    "plt.savefig('../../../plots/make_plots_plot_slope_vs_edge_dist_v4_andre.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "print(fit_res)\n",
    "print(fit_res.rvalue**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "\n",
    "df_fit_result = pd.DataFrame(fit_dict)\n",
    "df_corr = df_fit_result[['edge_dist', 'T', 'SIC', 'slope', 'STD']]\n",
    "### subtract the upper triangle\n",
    "\n",
    "rho = df_corr.corr()\n",
    "pval = df_corr.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "\n",
    "p = pval.map(lambda x: ''.join(['*' for t in [.05, .01, .001] if x<=t]))\n",
    "rho_star = rho.round(2).astype(str) + p\n",
    "\n",
    "mask = np.triu(np.ones_like(rho, dtype=bool))\n",
    "\n",
    "rho_star.mask(mask)\n",
    "rho_star.values[mask] = ''\n",
    "rho_star = rho_star.to_numpy()\n",
    "im = sns.heatmap(rho, mask=mask, cmap='PuOr_r', vmin=-1, vmax=1, annot=False, alpha=0.7, ax=ax)\n",
    "\n",
    "for i in range(rho_star.shape[0]):\n",
    "    for j in range(rho_star.shape[1]):\n",
    "        im.text(j+.5, i+.5, rho_star[i,j], ha='center', va='center', color='black', fontsize=8)\n",
    "\n",
    "ax.set_xticklabels(['Distance \\nMIZ edge', \n",
    "                     r'$T_\\mathrm{skin}$',\n",
    "                    'SIC', r'slope', \n",
    "                    ''])\n",
    "\n",
    "\n",
    "ax.set_yticklabels(['', \n",
    "                     r'$T_\\mathrm{skin}$',\n",
    "                    'SIC', r'slope', \n",
    "                    r'$\\sigma T_\\mathrm{skin}$'])\n",
    "\n",
    "ax.yaxis.set_ticks_position('none')\n",
    "ax.xaxis.set_ticks_position('none')\n",
    "\n",
    "plt.savefig('../../../plots/make_plots_corr_heatmap.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_area = ds.segment_size.sum()\n",
    "\n",
    "print('total area', total_area.values/1e4 ,'km²')\n",
    "\n",
    "spacing = 15\n",
    "\n",
    "dsgp_edge_dist = ds.groupby_bins('segment_edge_dist', np.linspace(0, 150, spacing))\n",
    "dsgp_label = ds.groupby('segment_label').sum()\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    columns=['Open Water', 'Snow Covered Ice', 'Thin Ice', 'Ice Water Mix'],\n",
    "    data = np.zeros((spacing-1, 4)),\n",
    "\n",
    "    #index=np.linspace(0, 200, 20)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "df = df[['Open Water', 'Ice Water Mix', 'Thin Ice', 'Snow Covered Ice']]\n",
    "\n",
    "#dsgp_edge_dist.segment_size.where(dsgp_edge_dist.segment_label == 2)\n",
    "\n",
    "for i, group in enumerate(dsgp_edge_dist):\n",
    "    open_water_area = group[1].segment_size.where(group[1].segment_label == 1).sum().values\n",
    "    snow_covered_ice_area = group[1].segment_size.where(group[1].segment_label == 3).sum().values\n",
    "    thin_ice_area = group[1].segment_size.where(group[1].segment_label == 4).sum().values\n",
    "    ice_water_mix_area = group[1].segment_size.where(group[1].segment_label == 2).sum().values\n",
    "\n",
    "    total_area = open_water_area + snow_covered_ice_area + thin_ice_area + ice_water_mix_area\n",
    "\n",
    "    df.loc[i, 'Open Water'] = open_water_area / total_area\n",
    "    df.loc[i, 'Snow Covered Ice'] = snow_covered_ice_area / total_area\n",
    "    df.loc[i, 'Thin Ice'] = thin_ice_area / total_area\n",
    "    df.loc[i, 'Ice Water Mix'] = ice_water_mix_area / total_area\n",
    "\n",
    "df.set_index(np.linspace(0, 150, spacing-1), inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3.15, 2))\n",
    "\n",
    "im = df.plot.area(stacked=True, cmap=cmap, ax=ax, alpha=.8, legend=False, linewidth=0, label='')\n",
    "\n",
    "\n",
    "#ax.legend(title='Surface type', loc='upper right', fontsize=6)\n",
    "### add a colorbar instead of a legend\n",
    "\n",
    "### make a colormap from listedcolors \n",
    "\n",
    "# from matplotlib.colors import ListedColormap\n",
    "\n",
    "# cmap = ListedColormap(colors)\n",
    "\n",
    "\n",
    "im = ax.contourf(np.array([[1, 2, 3, 4], [1, 2, 0, 4]]), cmap=cmap, alpha=1, levels=[0.5, 1.5, 2.5, 3.5, 4.5])\n",
    "im.set_visible(False)\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "\n",
    "cbar = fig.colorbar(im, cax=cax, orientation='vertical', ticks=[1, 2, 3, 4])\n",
    "cbar.set_ticklabels(['OW', 'IWM', 'TI', 'SC'], fontweight='bold')\n",
    "cbar.ax.yaxis.set_tick_params(width=0, length=0)\n",
    "cbar.ax.yaxis.set_ticks_position('none')\n",
    "cbar.ax.set_frame_on(False)\n",
    "### shift the colorbar to the right\n",
    "\n",
    "ax.axes.grid(True)\n",
    "imi = (1 - ds.groupby_bins('segment_edge_dist', np.linspace(0, 150, 50)).mean().segment_sic / 100).plot(ax=ax, color='r', linestyle='--', linewidth=1, zorder=100)\n",
    "\n",
    "label = ['MODIS/AMSR 1-SIC']\n",
    "handles = imi\n",
    "\n",
    "ax.legend(handles, label, loc='upper right', fontsize=8)\n",
    "\n",
    "ax.spines[['top', 'right']].set_visible(False)\n",
    "ax.set_xlabel('Distance to sea-ice edge (km)')\n",
    "# ax.text(-0.1, -0.35, '    Ice edge\\n   (SIC = 10%)\\n  ← Open Ocean', transform=ax.transAxes, fontweight='bold', fontsize=8)\n",
    "# #ax.text(-0.27, -0.2, '← Open Ocean\\n', transform=ax.transAxes, fontweight='bold', fontsize=6)\n",
    "# #ax.text(0.8, -0.2, '→\\n', transform=ax.transAxes, fontweight='bold', fontsize=6)\n",
    "# ax.text(.9, -0.35 , 'Internal  →\\nice zone \\n', transform=ax.transAxes, fontweight='bold', fontsize=8)\n",
    "ax.set_ylabel('Fraction of total area')\n",
    "ax.axes.grid(True)\n",
    "ax.set_xlim([0, 150])\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "plt.savefig('../../../plots/make_plots_stacked_bar_plot_with_SIC_andre_v4.png', bbox_inches='tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_area = ds.segment_size.sum()\n",
    "\n",
    "print('total area', total_area.values/1e4 ,'km²')\n",
    "\n",
    "spacing = 15\n",
    "\n",
    "dsgp_edge_dist = ds.groupby_bins('segment_edge_dist', np.linspace(0, 150, spacing))\n",
    "dsgp_label = ds.groupby('segment_label').sum()\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    columns=['Open Water', 'Snow Covered Ice', 'Thin Ice', 'Ice Water Mix'],\n",
    "    data = np.zeros((spacing-1, 4)),\n",
    "    #index=np.linspace(0, 200, 20)\n",
    ")\n",
    "\n",
    "def error_func(T):\n",
    "    if T < 100:\n",
    "        T += 273.15\n",
    "\n",
    "    e_atm_sca = 0.477\n",
    "    a_scs = 9.051  # K\n",
    "    b_scs = 0.967  # K^-1\n",
    "    e_atm_sca = 0.47  # K\n",
    "    NETD_B5 = 0.473  # K\n",
    "    a_b5 = 8.781  # K\n",
    "    b_b5 = -0.031  # K^-1\n",
    "    delta_T_B5 = (b_b5 * T + a_b5)\n",
    "    delta_T_S_sca = np.sqrt(e_atm_sca**2 + b_scs**2 * NETD_B5**2 + (b_scs * delta_T_B5)**2)\n",
    "    \n",
    "    return delta_T_S_sca\n",
    "\n",
    "\n",
    "df_error = pd.DataFrame(\n",
    "    columns=['Open Water', 'Snow Covered Ice', 'Thin Ice', 'Ice Water Mix'],\n",
    "    data = np.zeros((spacing-1, 4)),\n",
    ")\n",
    "\n",
    "\n",
    "df = df[['Open Water', 'Ice Water Mix', 'Thin Ice', 'Snow Covered Ice']]\n",
    "\n",
    "#dsgp_edge_dist.segment_size.where(dsgp_edge_dist.segment_label == 2)\n",
    "\n",
    "for i, group in enumerate(dsgp_edge_dist):\n",
    "    open_water_mean = group[1].segment_T.where(group[1].segment_label == 1).values\n",
    "    snow_covered_ice_mean = group[1].segment_T.where(group[1].segment_label == 3).values\n",
    "    thin_ice_mean = group[1].segment_T.where(group[1].segment_label == 4).values\n",
    "    ice_water_mix_mean = group[1].segment_T.where(group[1].segment_label == 2).values\n",
    "\n",
    "    open_water_area = group[1].segment_size.where(group[1].segment_label == 1).values\n",
    "    snow_covered_ice_area = group[1].segment_size.where(group[1].segment_label == 3).values\n",
    "    thin_ice_area = group[1].segment_size.where(group[1].segment_label == 4).values\n",
    "    ice_water_mix_area = group[1].segment_size.where(group[1].segment_label == 2).values\n",
    "\n",
    "\n",
    "    open_water_mean = np.nansum(open_water_mean * open_water_area) / np.nansum(open_water_area)\n",
    "    snow_covered_ice_mean = np.nansum(snow_covered_ice_mean * snow_covered_ice_area) / np.nansum(snow_covered_ice_area)\n",
    "    thin_ice_area = np.nansum(thin_ice_mean * thin_ice_area) / np.nansum(thin_ice_area)\n",
    "    ice_water_mix_area = np.nansum(ice_water_mix_mean * ice_water_mix_area) / np.nansum(ice_water_mix_area)\n",
    "\n",
    "\n",
    "    total_area = 1\n",
    "    df.loc[i, 'Open Water'] = open_water_mean / total_area\n",
    "    df.loc[i, 'Snow Covered Ice'] = snow_covered_ice_mean / total_area\n",
    "    df.loc[i, 'Thin Ice'] = thin_ice_area / total_area\n",
    "    df.loc[i, 'Ice Water Mix'] = ice_water_mix_area / total_area\n",
    "\n",
    "    df_error.loc[i, 'Open Water'] = error_func(open_water_mean)\n",
    "    df_error.loc[i, 'Snow Covered Ice'] = error_func(snow_covered_ice_mean)\n",
    "    df_error.loc[i, 'Thin Ice'] = error_func(thin_ice_area)\n",
    "    df_error.loc[i, 'Ice Water Mix'] = error_func(ice_water_mix_area)\n",
    "\n",
    "df.set_index(np.linspace(0, 150, spacing-1), inplace=True)\n",
    "df_error.set_index(np.linspace(0, 150, spacing-1), inplace=True)\n",
    "\n",
    "fig, (ax, ax2) = plt.subplots(1, 2, figsize=(3.15, 2),\n",
    "                               gridspec_kw={'width_ratios': [1, .3]},\n",
    "                               sharey=True)\n",
    "\n",
    "#im = df.plot(stacked=False, cmap=cmap, ax=ax, alpha=.8, legend=False, linewidth=0, label='')\n",
    "im = df.plot(cmap=cmap, alpha=.8, legend=False, label='', marker='o', ax=ax, markersize=2, linewidth=0)\n",
    "\n",
    "#ax.legend(title='Surface type', loc='upper right', fontsize=6)\n",
    "### add a colorbar instead of a legend\n",
    "\n",
    "### make a colormap from listedcolors \n",
    "\n",
    "# from matplotlib.colors import ListedColormap\n",
    "\n",
    "# cmap = ListedColormap(colors)\n",
    "\n",
    "means = df.mean()\n",
    "means_label = [1, 2, 3, 4]\n",
    "\n",
    "#ax2.scatter([0,0,0,0], means, c=means_label, cmap=cmap, edgecolors='k', lw=.5, s=50)\n",
    "ax2.set_xticks([])\n",
    "ax2.spines[['top', 'right', 'bottom']].set_visible(False)\n",
    "\n",
    "im = ax.contourf(np.array([[1, 2, 3, 4], [1, 2, 0, 4]]), cmap=cmap, alpha=1, levels=[0.5, 1.5, 2.5, 3.5, 4.5])\n",
    "im.set_visible(False)\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = divider.append_axes('right', size='50%', pad=0.05)\n",
    "\n",
    "cbar = fig.colorbar(im, cax=cax, orientation='vertical', ticks=[1, 2, 3, 4])\n",
    "cbar.set_ticklabels(['Open\\nWater', 'Ice Water\\nMix', 'Thin\\nIce', 'Snow Covered\\nIce'])\n",
    "cbar.set_ticklabels(['OW', 'IWM', 'TI', 'SC'], fontweight='bold')\n",
    "cbar.ax.yaxis.set_tick_params(width=0, length=0)\n",
    "cbar.ax.yaxis.set_ticks_position('none')\n",
    "cbar.ax.set_frame_on(False)\n",
    "\n",
    "colors = np.array([[0.10588235, 0.61960784, 0.46666667, 1.],\n",
    "                [0.45882353, 0.43921569, 0.70196078, 1.],\n",
    "                [0.4       , 0.4       , 0.4       , 1.],\n",
    "                [0.90196078, 0.67058824, 0.00784314, 1.],\n",
    "])\n",
    "\n",
    "print(error_func(273.15))   \n",
    "\n",
    "ax.axes.grid(True)\n",
    "# imi = (1 - ds.groupby_bins('segment_edge_dist', np.linspace(0, 150, 50)).mean().segment_sic / 100).plot(ax=ax, color='r', linestyle='--', linewidth=1, zorder=100)\n",
    "\n",
    "# label = ['MODIS/AMSR 1-SIC']\n",
    "# handles = imi\n",
    "\n",
    "# ax.legend(handles, label, loc='upper right', fontsize=8)\n",
    "\n",
    "ax.spines[['top', 'right']].set_visible(False)\n",
    "ax.set_xlabel('distance (km)')\n",
    "# ax.text(-0.1, -0.35, '    Ice edge\\n   (SIC = 10%)\\n  ← Open Ocean', transform=ax.transAxes, fontweight='bold', fontsize=8)\n",
    "# #ax.text(-0.27, -0.2, '← Open Ocean\\n', transform=ax.transAxes, fontweight='bold', fontsize=6)\n",
    "# #ax.text(0.8, -0.2, '→\\n', transform=ax.transAxes, fontweight='bold', fontsize=6)\n",
    "# ax.text(.9, -0.35 , 'Internal  →\\nice zone \\n', transform=ax.transAxes, fontweight='bold', fontsize=8)\n",
    "ax.set_ylabel('$T_\\mathrm{S}$ (°C)')\n",
    "ax.axes.grid(True)\n",
    "#ax.set_xlim([0, 150])\n",
    "# ax.set_ylim([0, 1])\n",
    "ax.set_xlabel('Distance to sea-ice edge (km)')\n",
    "\n",
    "\n",
    "ax.text(0.05, 0.95, 'a', transform=ax.transAxes, fontsize=10, fontweight='bold', va='top')\n",
    "ax2.text(0.05, 0.95, 'b', transform=ax2.transAxes, fontsize=10, fontweight='bold', va='top')\n",
    "\n",
    "\n",
    "#### fill a sheded area with the error + - the mean \n",
    "\n",
    "total_error  = (df.std()**2 + df_error.mean()**2)**.5\n",
    "\n",
    "for i, col in enumerate(df.columns):\n",
    "    #ax.fill_between(df.index, df.loc[:, col] - df_error.loc[:, col], df.loc[:, col] + df_error.loc[:, col], alpha=.4, color=colors[i])\n",
    "\n",
    "    ax.errorbar(df.index, df.loc[:, col], yerr=df_error.loc[:, col], fmt='o', color=colors[i], markersize=3, label=col, capsize=3, capthick=2, markeredgecolor='black', markeredgewidth=.7)\n",
    "    ax2.errorbar([0], means[col], yerr=total_error[col], fmt='o', color=colors[i], markersize=3, label='Total error', capsize=3, capthick=2, markeredgecolor='black', markeredgewidth=.7)\n",
    "\n",
    "\n",
    "ax.set_xlim([-5, 150])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('../../../plots/make_plots_stacked_bar_plot_temperature_errors_v5.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "for m, e in zip(means, total_error):\n",
    "    print(f'{m:.2f} ± {e:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "label_dict = {1: 'Open Water', 2: 'Ice Water Mix', 3: 'Thin Ice', 4: 'Snow Covered'}\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(4, 1, figsize=(4, 3))\n",
    "\n",
    "\n",
    "for label in [1, 2, 3, 4]:\n",
    "\n",
    "    print(f'Label {label}: {label_dict[label]}')\n",
    "\n",
    "    dsgp = ds.where(ds['segment_label'] == label).groupby_bins('segment_edge_dist', np.linspace(0, 350, 36)).mean()\n",
    "\n",
    "    df = dsgp[['segment_edge_dist', 'segment_size', 'segment_T', 'segment_std']].to_pandas()\n",
    "\n",
    "\n",
    "\n",
    "    # this computes the correlation coefficients\n",
    "    corr = df.corr(method=lambda x, y: pearsonr(x, y)[0]) \n",
    "\n",
    "    # this computes the p-values\n",
    "    pvalues = df.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(len(df.columns)) \n",
    "\n",
    "\n",
    "    # from scipy.stats import pearsonr\n",
    "    # import numpy as np\n",
    "    # rho = df.corr()\n",
    "    # pval = df.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "    # p = pval.map(lambda x: ''.join(['*' for t in [.05, .01, .001] if x<=t]))\n",
    "    # rho = rho.round(2).astype(str) + p\n",
    "\n",
    "    # mask = np.triu(np.ones_like(rho, dtype=bool))\n",
    "\n",
    "    # rho.mask(mask)\n",
    "    # rho.values[mask] = ''\n",
    "    # print(rho)\n",
    "    # print('')\n",
    "    # print('---' *40)\n",
    "    # print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sic.time.size / 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba_josh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
