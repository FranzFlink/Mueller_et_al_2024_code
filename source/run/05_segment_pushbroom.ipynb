{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2d9fcdc-6b2e-4a85-8f01-d3a087dbb99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Sucessfully imported SAM\n"
     ]
    }
   ],
   "source": [
    "#%pip install sympy\n",
    "import xarray as xr\n",
    "#import dask.array as da\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "import os\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_TYPE = \"vit_h\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint='../model/sam_vit_h_4b8939.pth')\n",
    "sam.to(device=DEVICE)\n",
    "\n",
    "print('Sucessfully imported SAM')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92e2b395-1c0f-4c15-b8ae-13e46873ae2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m input_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_sam/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_sam/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m processed_files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(output_path)\n\u001b[1;32m      7\u001b[0m processed_files\u001b[38;5;241m.\u001b[39msort()\n\u001b[1;32m      8\u001b[0m processed_files\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "## check which files are already processed and which still need processing: \n",
    "\n",
    "input_path = 'input_sam/'\n",
    "output_path = 'output_sam/'\n",
    "\n",
    "processed_files = os.listdir(output_path)\n",
    "processed_files.sort()\n",
    "processed_files\n",
    "\n",
    "to_do = os.listdir(input_path)\n",
    "to_do.sort()\n",
    "\n",
    "to_do = [os.path.join('~/input_sam', f) for f in to_do]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa3f236c-8642-4ad0-befa-48c0ee1e9516",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def timing_wrapper(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"Executed {func.__name__} in {(end - start):.2f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timing_wrapper\n",
    "def predict_sam(image, generator):\n",
    "    return generator.generate(image)\n",
    "\n",
    "\n",
    "@timing_wrapper\n",
    "def sam_result_to_ds(ds, sam_result):\n",
    "    \n",
    "    ds_ny, ds_nx = ds.dims['y'], ds.dims['x']\n",
    "    \n",
    "    ny, nx = sam_result[0]['segmentation'].shape\n",
    "    \n",
    "    nseg = len(sam_result)\n",
    "    \n",
    "    da_segmentation = da.zeros((ny, nx)).astype('int')\n",
    "    da_area = da.zeros(nseg)\n",
    "    da_bbox = da.zeros((nseg, 4))\n",
    "    da_iou = da.zeros(nseg)\n",
    "    da_stabscore = da.zeros(nseg)\n",
    "    da_coords =  da.zeros(nseg).astype('int')\n",
    "    da_pcoords = da.zeros((nseg, 2))   \n",
    "    \n",
    "    output_ds = xr.Dataset(\n",
    "        data_vars = {\n",
    "            'segmentation' : (('y', 'x'), da_segmentation),\n",
    "            'area' : (('seg'), da_area),\n",
    "            'bbox' : (('seg', 'bbox_coords'), da_bbox),\n",
    "            'predicted_iou' : (('seg'), da_iou),\n",
    "            'stability_score' : (('seg'), da_stabscore),\n",
    "            'point_coords' : (('seg', 'p_coords'), da_pcoords)\n",
    "        },\n",
    "        coords = {\n",
    "            'seg' : np.arange(nseg),\n",
    "            'x' : ds.x.values,\n",
    "            'y' : ds.y.values,\n",
    "            'bbox_coords' : [0, 1, 2, 3],\n",
    "            'p_coords' : [0, 1]\n",
    "        },\n",
    "    )\n",
    "\n",
    "    for i, seg in enumerate(sam_result):\n",
    "        for key, value in seg.items():\n",
    "            \n",
    "            if key in ['segmentation', 'area', 'predicted_iou', 'stability_score', 'point_coords', 'bbox']:\n",
    "                if key == 'segmentation':\n",
    "                    output_ds[key] += value * (i+1)\n",
    "                else:\n",
    "                    output_ds[key][i] = np.array(value).squeeze()\n",
    "\n",
    "    return output_ds \n",
    "\n",
    "\n",
    "@timing_wrapper\n",
    "def main_pushbroom(infile, outfile, variable='bt_1', xindex=None, sam=sam, mask_gen_params=None):\n",
    "    \n",
    "    if xindex.any():\n",
    "        ds = xr.open_dataset(infile).sel(x=xindex)\n",
    "    else: \n",
    "        ds = xr.open_dataset(infile)\n",
    "        \n",
    "    #outfile = infile.replace('input', 'output')\n",
    "    \n",
    "    if mask_gen_params is None:\n",
    "        mask_gen_params = {\n",
    "            'model': sam,\n",
    "            'points_per_side': 4,\n",
    "            'pred_iou_thresh': 0.86,\n",
    "            'stability_score_thresh': 0.92,\n",
    "            'crop_n_layers': 1,\n",
    "            'crop_n_points_downscale_factor': 2,\n",
    "            'min_mask_region_area': 100  # Requires open-cv to run post-processing\n",
    "        }\n",
    "        \n",
    "    mask_generator = SamAutomaticMaskGenerator(**mask_gen_params)\n",
    "        \n",
    "    if variable == 'bt_1':\n",
    "    \n",
    "    ### scale the data to [0, 1] interval, scale by 256 for image representation and convert to uint \n",
    "    \n",
    "        bt_1_scaled = (ds.bt_1 - ds.bt_1.min()) /  (ds.bt_1.max() - ds.bt_1.min())\n",
    "\n",
    "\n",
    "        RGB = xr.concat([bt_1_scaled, bt_1_scaled, bt_1_scaled], dim='variable') * 255\n",
    "        RGB = RGB.astype('uint8').transpose('y', 'x', 'variable').values\n",
    "\n",
    "    elif variable == 'proba':\n",
    "\n",
    "        RGB = (ds[['cl_0', 'cl_1', 'cl_2']].to_array().transpose('y', 'x', 'variable') * 255).astype('uint8').values\n",
    "\n",
    "    sam_result = predict_sam(RGB, mask_generator)\n",
    "    ds_result = sam_result_to_ds(ds, sam_result)\n",
    "    \n",
    "    ds_result['pred_proba'] = (('surface_class', 'y', 'x'),  (ds.drop_vars(['bt_1', 'lat', 'lon', 'skin_t']).to_array().values * 100).astype('uint8'))\n",
    "    #outfile = outfile.replace('concat', f'sam_predict_{xindex[0]}_{xindex[-1]}')\n",
    "    \n",
    "    attrs = {}\n",
    "    \n",
    "    for key, value in mask_gen_params.items():\n",
    "        if key != 'model':\n",
    "            attrs[f'sam_param:{key}'] = value\n",
    "            \n",
    "    ds_result.attrs = attrs\n",
    "    \n",
    "    print(outfile)\n",
    "    ds_result.to_netcdf(outfile, mode='w')\n",
    "    \n",
    "    return ds_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e818ceb2-5744-4064-a194-315bc695c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_expected_output_files(infile):\n",
    "    \n",
    "    ds = xr.open_dataset(infile)\n",
    "\n",
    "\n",
    "    dirname = infile.split('/')[-1].split('_concat.nc')[0]\n",
    "    dirname = os.path.join('/home/sc.uni-leipzig.de/jn906hluu/output_sam/', dirname)\n",
    "    if not os.path.isdir(dirname):\n",
    "        os.mkdir(dirname)\n",
    "\n",
    "    else:\n",
    "        print(f'{dirname} already exists \\nNumber of files: {len(os.listdir(dirname))} ')\n",
    "\n",
    "    print(f'dataset x-size: {ds.x.size}')\n",
    "\n",
    "    splits =np.ceil(ds.x.size / 5000)\n",
    "    x_index = np.array_split(ds['x'].values, splits)\n",
    "\n",
    "    date = infile.split('/')[-1].split('T')[0]\n",
    "\n",
    "    expected_outputs = [f'{date}_sam_predict_{x[0]}_{x[-1]}.nc' for x in x_index]\n",
    "    expected_outputs = [os.path.join(dirname, f) for f in expected_outputs]\n",
    "    expected_outputs\n",
    "\n",
    "    ds.close()\n",
    "    \n",
    "    return expected_outputs, x_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e3f045-b1c9-41ca-9bd7-61b737fd71df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-03-20T10:35:00_2022-03-20T10:50:00 already exists \n",
      "Number of files: 11 \n",
      "dataset x-size: 20302\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-03-20T11:20:00_2022-03-20T11:26:00 already exists \n",
      "Number of files: 4 \n",
      "dataset x-size: 7561\n",
      "Skipping\n",
      "Skipping\n",
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-03-21T11:39:00_2022-03-21T11:44:00 already exists \n",
      "Number of files: 3 \n",
      "dataset x-size: 6199\n",
      "Skipping\n",
      "Skipping\n",
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-03-28T10:28:00_2022-03-28T11:05:00 already exists \n",
      "Number of files: 12 \n",
      "dataset x-size: 57413\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-03-28T13:13:30_2022-03-28T13:21:30 already exists \n",
      "Number of files: 3 \n",
      "dataset x-size: 12929\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-03-28T14:12:30_2022-03-28T14:27:00 already exists \n",
      "Number of files: 5 \n",
      "dataset x-size: 22304\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-03-29T14:27:00_2022-03-29T14:37:30 already exists \n",
      "Number of files: 3 \n",
      "dataset x-size: 13100\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-03-30T09:46:30_2022-03-30T09:52:00 already exists \n",
      "Number of files: 2 \n",
      "dataset x-size: 8047\n",
      "Skipping\n",
      "Skipping\n",
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-04-01T09:25:00_2022-04-01T09:32:30 already exists \n",
      "Number of files: 3 \n",
      "dataset x-size: 10784\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-04-01T10:21:00_2022-04-01T10:54:00 already exists \n",
      "Number of files: 10 \n",
      "dataset x-size: 48025\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-04-01T11:22:30_2022-04-01T11:43:30 already exists \n",
      "Number of files: 7 \n",
      "dataset x-size: 31174\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-04-01T12:20:00_2022-04-01T12:51:00 already exists \n",
      "Number of files: 10 \n",
      "dataset x-size: 45284\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-04-01T13:36:00_2022-04-01T13:52:30 already exists \n",
      "Number of files: 5 \n",
      "dataset x-size: 23226\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-04-04T09:18:30_2022-04-04T09:23:30 already exists \n",
      "Number of files: 2 \n",
      "dataset x-size: 6319\n",
      "Skipping\n",
      "Skipping\n",
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-04-04T12:24:00_2022-04-04T13:01:00 already exists \n",
      "Number of files: 10 \n",
      "dataset x-size: 48035\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-04-04T13:19:30_2022-04-04T13:40:00 already exists \n",
      "Number of files: 11 \n",
      "dataset x-size: 26944\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "/home/sc.uni-leipzig.de/jn906hluu/output_sam/2022-04-04T14:08:00_2022-04-04T14:30:00 already exists \n",
      "Number of files: 6 \n",
      "dataset x-size: 28407\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n"
     ]
    }
   ],
   "source": [
    "for infile in to_do:\n",
    "    \n",
    "    expected_outputs, x_index = list_expected_output_files(infile)\n",
    "    \n",
    "    for output, index in zip(expected_outputs, x_index):\n",
    "        \n",
    "        if not os.path.isfile(output):\n",
    "            print(f'Processing {output}')\n",
    "            \n",
    "            ds_result = main_pushbroom(infile, output, xindex=index,\n",
    "                 mask_gen_params = {\n",
    "                    'model': sam,\n",
    "                    'points_per_side': 256,\n",
    "                    'pred_iou_thresh': 0.86,\n",
    "                    'stability_score_thresh': 0.92,\n",
    "                    'crop_n_layers': 3,\n",
    "                    'crop_n_points_downscale_factor': 2,\n",
    "                    'min_mask_region_area': 100  # Requires open-cv to run post-processing\n",
    "                    }     \n",
    "                )\n",
    "\n",
    "            \n",
    "        else: \n",
    "            print('Skipping')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
